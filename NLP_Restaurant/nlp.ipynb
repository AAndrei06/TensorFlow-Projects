{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ZeRIo6rTdVMMyVJW_zaJF7vajm6hmKt_","authorship_tag":"ABX9TyPXq3cSWa4CgS5nDBKC2ay7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":371,"metadata":{"id":"6dyv0Ab8h71j","executionInfo":{"status":"ok","timestamp":1722272503328,"user_tz":-180,"elapsed":627,"user":{"displayName":"Andrei Arseni","userId":"03424520132914936940"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import pandas as pd\n","import numpy as np\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","from collections import Counter\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/nlp_project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iZdcpBsvkeX","executionInfo":{"status":"ok","timestamp":1722272504970,"user_tz":-180,"elapsed":14,"user":{"displayName":"Andrei Arseni","userId":"03424520132914936940"}},"outputId":"b3b91b1d-6ee9-456d-c578-d8a430cd7e6f"},"execution_count":372,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/nlp_project\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('data.csv').dropna().drop(['Country','Restaurant Name','Review Title','Review Date'],axis = 1)\n","\n","labels = ['Negative','Positive']\n","\n","def change_labels(cell):\n","    return int(list(labels).index(cell))\n","\n","df.Sentiment = df['Sentiment'].apply(change_labels)\n","\n","def remove_punct(cell):\n","    translator = str.maketrans(\"\",\"\",string.punctuation)\n","    return cell.translate(translator)\n","df.Review = df.Review.map(remove_punct)\n","\n","nltk.download('stopwords')\n","stop = set(stopwords.words('english'))\n","def remove_stopwords(text):\n","    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n","    return \" \".join(filtered_words)\n","df.Review = df.Review.map(remove_stopwords)"],"metadata":{"id":"Vn20YZ3ajPpa","executionInfo":{"status":"ok","timestamp":1722272505776,"user_tz":-180,"elapsed":4,"user":{"displayName":"Andrei Arseni","userId":"03424520132914936940"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f0a6de64-4f2e-4d84-b4f9-5ad028d7cbe1"},"execution_count":373,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["def count(data_column):\n","    count = Counter()\n","    for text in data_column:\n","        for word in text.split():\n","            count[word] += 1\n","    return count\n","\n","counter = count(df.Review)\n","nr_unique_words = len(counter)"],"metadata":{"id":"cL0RRo7kmHfX","executionInfo":{"status":"ok","timestamp":1722272507417,"user_tz":-180,"elapsed":6,"user":{"displayName":"Andrei Arseni","userId":"03424520132914936940"}}},"execution_count":374,"outputs":[]},{"cell_type":"code","source":["train_size = int(df.shape[0]*0.8)\n","df = df.sample(frac=1).reset_index(drop=True)\n","train_df = df[:train_size]\n","test_df = df[train_size:]\n","\n","train_sentences = train_df.Review.to_numpy()\n","train_labels = train_df.Sentiment.to_numpy()\n","test_sentences = test_df.Review.to_numpy()\n","test_labels = test_df.Sentiment.to_numpy()"],"metadata":{"id":"cqfI7snsnhKC","executionInfo":{"status":"ok","timestamp":1722272508217,"user_tz":-180,"elapsed":10,"user":{"displayName":"Andrei Arseni","userId":"03424520132914936940"}}},"execution_count":375,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words = nr_unique_words)\n","tokenizer.fit_on_texts(train_sentences)\n","\n","word_dict = tokenizer.word_index\n","train_sequences = tokenizer.texts_to_sequences(train_sentences)\n","test_sequences = tokenizer.texts_to_sequences(test_sentences)\n","\n","max_length = 200\n","\n","train_padded = pad_sequences(train_sequences, maxlen = max_length, padding = 'post',truncating = 'post')\n","test_padded = pad_sequences(test_sequences, maxlen = max_length, padding = 'post',truncating = 'post')\n","reverse_word_index = dict([(idx,word) for (word,idx) in word_dict.items()])\n","def decode(sequence):\n","    return \" \".join([reverse_word_index.get(idx,'?') for idx in sequence])"],"metadata":{"id":"2ReWYrmhp1mf","executionInfo":{"status":"ok","timestamp":1722272511062,"user_tz":-180,"elapsed":573,"user":{"displayName":"Andrei Arseni","userId":"03424520132914936940"}}},"execution_count":376,"outputs":[]},{"cell_type":"code","source":["model = keras.models.Sequential(\n","    [\n","        layers.Embedding(nr_unique_words, 32, input_length = max_length),\n","        layers.Bidirectional(layers.LSTM(64,dropout = 0.1)),\n","        layers.Dense(32,activation = 'relu'),\n","        layers.Dense(16,activation = 'relu'),\n","        layers.Dense(8,activation = 'relu'),\n","        layers.Dense(2,activation = 'softmax')\n","    ]\n",")\n","\n","model.summary()\n","\n","model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n","    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n","    metrics = ['accuracy']\n",")\n","\n","model.fit(train_padded, train_labels, epochs = 10,validation_data = (test_padded, test_labels), verbose = True)\n","model.evaluate(test_padded, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ho38XPfntgLR","executionInfo":{"status":"ok","timestamp":1722272607312,"user_tz":-180,"elapsed":95584,"user":{"displayName":"Andrei Arseni","userId":"03424520132914936940"}},"outputId":"02bb2b3d-604b-4462-b89f-109b9177afb1"},"execution_count":377,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_14\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_14 (Embedding)    (None, 200, 32)           214304    \n","                                                                 \n"," bidirectional_14 (Bidirect  (None, 128)               49664     \n"," ional)                                                          \n","                                                                 \n"," dense_39 (Dense)            (None, 32)                4128      \n","                                                                 \n"," dense_40 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_41 (Dense)            (None, 8)                 136       \n","                                                                 \n"," dense_42 (Dense)            (None, 2)                 18        \n","                                                                 \n","=================================================================\n","Total params: 268778 (1.03 MB)\n","Trainable params: 268778 (1.03 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","38/38 [==============================] - 16s 303ms/step - loss: 0.4703 - accuracy: 0.8293 - val_loss: 0.3990 - val_accuracy: 0.8007\n","Epoch 2/10\n","38/38 [==============================] - 7s 192ms/step - loss: 0.2682 - accuracy: 0.8293 - val_loss: 0.2930 - val_accuracy: 0.8007\n","Epoch 3/10\n","38/38 [==============================] - 10s 261ms/step - loss: 0.1419 - accuracy: 0.9592 - val_loss: 0.3193 - val_accuracy: 0.9037\n","Epoch 4/10\n","38/38 [==============================] - 8s 217ms/step - loss: 0.1022 - accuracy: 0.9917 - val_loss: 0.1758 - val_accuracy: 0.9535\n","Epoch 5/10\n","38/38 [==============================] - 9s 225ms/step - loss: 0.0291 - accuracy: 0.9958 - val_loss: 0.1431 - val_accuracy: 0.9601\n","Epoch 6/10\n","38/38 [==============================] - 8s 223ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9535\n","Epoch 7/10\n","38/38 [==============================] - 9s 227ms/step - loss: 4.3168e-04 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9601\n","Epoch 8/10\n","38/38 [==============================] - 10s 261ms/step - loss: 2.2665e-04 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9535\n","Epoch 9/10\n","38/38 [==============================] - 7s 191ms/step - loss: 1.5378e-04 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9601\n","Epoch 10/10\n","38/38 [==============================] - 9s 246ms/step - loss: 1.1329e-04 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9535\n","10/10 [==============================] - 0s 44ms/step - loss: 0.1789 - accuracy: 0.9535\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.17887690663337708, 0.9534883499145508]"]},"metadata":{},"execution_count":377}]},{"cell_type":"code","source":["def encode(text):\n","    arr = list()\n","    for i in text.split():\n","        arr.append(word_dict.get(i,0))\n","    t = list()\n","    t.append(arr)\n","    arr = pad_sequences(t, maxlen = max_length, padding = 'post',truncating = 'post')\n","    return np.array(arr)\n","\n","pred = model.predict(encode('The food was good and the staff was friendly'))\n","print(pred)\n","print(labels[np.argmax(pred)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3nxeI-1HACM5","executionInfo":{"status":"ok","timestamp":1722272736962,"user_tz":-180,"elapsed":365,"user":{"displayName":"Andrei Arseni","userId":"03424520132914936940"}},"outputId":"ceb1c27c-4727-433c-840b-4fd5ee2ebd84"},"execution_count":389,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 35ms/step\n","[[1.9147257e-04 9.9980861e-01]]\n","Positive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Ft_oC9c1cwGA"},"execution_count":null,"outputs":[]}]}